{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import wave\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import pysrt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"env.json\") as f: # input your env file path\n",
    "    envs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker ='counselor' # or customer\n",
    "\n",
    "# 데이터 파일명 형식 통일\n",
    "non_matching_files = []\n",
    "pattern = re.compile(r\"\\d{4}-\\d{2}-\\d{2}_\\d{6}__[Pp]\\d{1,2}\\.txt\")\n",
    "\n",
    "\n",
    "origin_path = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO',str(speaker))\n",
    "for root, _, files in os.walk(origin_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt') and not pattern.match(file):\n",
    "            non_matching_files.append(os.path.join(root, file))\n",
    "\n",
    "#  수동으로 파일 이름 수정\n",
    "for file in non_matching_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path,file_name,audio_path):\n",
    "\n",
    "    y, sr = librosa.load(file_path, sr=8000)# 오디오 파일 로드\n",
    "    y = nr.reduce_noise(y=y, sr=sr) # 잡음 제거\n",
    "\n",
    "    # Extraction 준비\n",
    "    frame = 0.025 # 25ms\n",
    "    sliding = 0.01 # 10ms\n",
    "    n_fft = int(round(frame * sr))\n",
    "    hop_length = int(round(sliding * sr))\n",
    "\n",
    "\n",
    "    # 특성 추출\n",
    "    features = {\n",
    "        'f0': librosa.pyin(y, fmin=85, fmax=400, frame_length=n_fft, hop_length=hop_length)[0], # 음성 특징을 반영한 fmin, fmax\n",
    "        'energy': librosa.feature.rms(y=y, frame_length=n_fft, hop_length=hop_length).flatten(),\n",
    "        'mfccs': librosa.feature.mfcc(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=13, window='hamming'),\n",
    "        'spec_bw': librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length).flatten(),\n",
    "        'zcr': librosa.feature.zero_crossing_rate(y=y, frame_length=n_fft, hop_length=hop_length).flatten(),\n",
    "        'cent': librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, window='hamming').flatten(),\n",
    "        'voiced_flag': librosa.pyin(y, fmin=85, fmax=400, frame_length=n_fft, hop_length=hop_length)[1],\n",
    "        'rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, roll_percent=0.99).flatten(),\n",
    "        'rolloff_min': librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, roll_percent=0.01).flatten(),\n",
    "        'contrast': librosa.feature.spectral_contrast(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, fmin=85), \n",
    "    }\n",
    "\n",
    "    # Transpose mfccs and contrast\n",
    "    features['mfccs'] = features['mfccs'].T\n",
    "    features['contrast'] = features['contrast'].T\n",
    "\n",
    "    # Find the minimum length of all features\n",
    "    min_length = min([len(x) for x in features.values()])\n",
    "\n",
    "    # Truncate all features to the same length\n",
    "    for key in features.keys():\n",
    "        features[key] = features[key][:min_length]\n",
    "\n",
    "    # Split the mfccs into individual columns\n",
    "    mfcc_columns = {}\n",
    "    for j in range(features['mfccs'].shape[1]):\n",
    "        mfcc_columns[f'mfcc_{j + 1}'] = features['mfccs'][:, j]\n",
    "    \n",
    "    # Split the contrast into individual columns\n",
    "    contrast_columns = {}\n",
    "    for j in range(features['contrast'].shape[1]):\n",
    "        contrast_columns[f'contrast_{j + 1}'] = features['contrast'][:, j]\n",
    "\n",
    "    # Update the features dictionary with the individual columns\n",
    "    del features['mfccs']\n",
    "    del features['contrast']\n",
    "    features.update(mfcc_columns)\n",
    "    features.update(contrast_columns)\n",
    "\n",
    "    # Save features into a DataFrame\n",
    "    df = pd.DataFrame(features)\n",
    "    \n",
    "    output_file = os.path.join(audio_path,file_name).replace(\".wav\",\".csv\")\n",
    "    df.to_csv(output_file,index=False)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오디오 파일 루트 디렉토리 설정\n",
    "speaker = 'counselor' # or customer\n",
    "\n",
    "audio_root = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO',str(speaker))\n",
    "\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(audio_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append([os.path.join(root, file),file])\n",
    "\n",
    "\n",
    "speaker = 'worker'\n",
    "audio_dest_root = os.path.join(envs['DATA_PATH'],'3_feature_extraction','CAL_AUDIO',str(speaker))\n",
    "for file_path,file_name in file_list: # 중간에 끊겼던 부분부터 시작\n",
    "    extract_features(file_path,file_name,audio_dest_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLD Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker ='worker'\n",
    "folder_path = os.path.join(envs['DATA_PATH'],'3_feature_extraction','CAL_AUDIO',str(speaker))\n",
    "summary_data = []\n",
    "\n",
    "# Iterate over all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Calculate mean, std, min, and max for each column\n",
    "        summary = df.describe().loc[['mean', 'std', 'min', 'max']].T\n",
    "        summary['file'] = filename\n",
    "        summary_data.append(summary)\n",
    "\n",
    "# Combine all summary DataFrames into one\n",
    "new_df = pd.concat(summary_data)\n",
    "new_df = new_df.reset_index()\n",
    "grouped_new_df = new_df.groupby(['file', 'index']).agg(\n",
    "    mean=('mean', 'mean'),\n",
    "    std=('std', 'mean'),\n",
    "    min=('min', 'mean'),\n",
    "    max=('max', 'mean')\n",
    ").reset_index()\n",
    "new_df_pivoted = grouped_new_df.pivot_table(index='file', columns='index', values=['mean', 'std', 'min', 'max'])\n",
    "new_df_pivoted.columns = ['_'.join(col).strip() for col in new_df_pivoted.columns.values]\n",
    "\n",
    "# Reset the index to bring 'file' back as a column\n",
    "new_df_pivoted = new_df_pivoted.reset_index()\n",
    "\n",
    "\n",
    "# Save data\n",
    "import re\n",
    "new_df_pivoted['file'] = new_df_pivoted['file'].apply(lambda x: str(x).replace('.csv',''))\n",
    "filename_pattern = re.compile(r'^\\d{4}-\\d{2}-\\d{2}_\\d{6}__P\\d{2}$')\n",
    "def filename_matching(file_name):\n",
    "    if not filename_pattern.match(file_name):\n",
    "        # 파일 이름 수정 작업\n",
    "        new_filename = file_name\n",
    "\n",
    "        # '_'가 하나만 있는 경우 수정\n",
    "        if \"_\" not in file_name.split('_')[-1]:\n",
    "            new_filename = new_filename.replace(r'\\d+_P', '__P')\n",
    "\n",
    "        # 소문자 p로 되어 있는 경우 수정\n",
    "        if 'p' in new_filename:\n",
    "            new_filename = new_filename.replace('p', 'P')\n",
    "        \n",
    "        return new_filename\n",
    "    return file_name\n",
    "new_df_pivoted['file']= new_df_pivoted['file'].apply(filename_matching)\n",
    "new_df_pivoted['pnum'] = new_df_pivoted['file'].apply(lambda x : str(x)[-2:])\n",
    "new_df_pivoted['start_second'] = new_df_pivoted['file'].apply(lambda x : str(x)[:17])\n",
    "\n",
    "new_df_pivoted.loc[new_df_pivoted['pnum'] == \"남희\", 'pnum'] = 15 \n",
    "new_df_pivoted['pnum']  =  new_df_pivoted['pnum'].astype('int')\n",
    "new_df_pivoted['start_second'] = pd.to_datetime(new_df_pivoted['start_second'],format='%Y-%m-%d_%H%M%S')\n",
    "\n",
    "new_df_pivoted.drop(['file'],axis=1,inplace=True)\n",
    "# new_df_pivoted.to_csv(f'/home/iclab/23EmoWorkerField/3_feature_extraction/CALL_AUDO_statistics/{speaker}_audio.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utterance feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화자별 음성 길이\n",
    "file_list = []\n",
    "speaker = \"customer\"\n",
    "\n",
    "audio_root =os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO',str(speaker))\n",
    "for root, dirs, files in os.walk(audio_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append([os.path.join(root, file),file])\n",
    "\n",
    "audio_additional_root = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO','audio_additional',str(speaker))\n",
    "for root, dirs, files in os.walk(audio_additional_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append([os.path.join(root, file),file])\n",
    "\n",
    "        \n",
    "# 정규 표현식 패턴으로 추출하기\n",
    "dt_pattern = r'\\d{4}-\\d{2}-\\d{2}_\\d{6}'\n",
    "pnum_pattern = r'[Pp](\\d{1,2})'\n",
    "\n",
    "# 파일 정보 저장을 위한 리스트\n",
    "data = []\n",
    "\n",
    "# 파일 이름에서 정보 추출 및 wav 파일 duration 계산\n",
    "for file_path, file_name in file_list:\n",
    "    # pnum 추출\n",
    "    pnum_match = re.search(pnum_pattern, file_name)\n",
    "    pnum = int(pnum_match.group()[-2:])\n",
    "    # start_second 추출\n",
    "    start_match = re.search(dt_pattern, file_name)\n",
    "    start_second = start_match.group()\n",
    "\n",
    "    # duration 계산\n",
    "    with wave.open(file_path, 'rb') as wav_file:\n",
    "        frames = wav_file.getnframes()\n",
    "        rate = wav_file.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "    \n",
    "    # 데이터 추가\n",
    "    data.append([pnum, start_second, duration])\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "customer_df = pd.DataFrame(data, columns=['pnum', 'start_second', 'customer_audio_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "speaker = \"worker\"\n",
    "\n",
    "audio_root = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO',str(speaker))\n",
    "for root, dirs, files in os.walk(audio_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append([os.path.join(root, file),file])\n",
    "\n",
    "audio_additional_root = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO','audio_additional',str(speaker))\n",
    "for root, dirs, files in os.walk(audio_additional_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append([os.path.join(root, file),file])\n",
    "\n",
    "        \n",
    "# 정규 표현식 패턴으로 추출하기\n",
    "dt_pattern = r'\\d{4}-\\d{2}-\\d{2}_\\d{6}'\n",
    "pnum_pattern = r'[Pp](\\d{1,2})'\n",
    "\n",
    "# 파일 정보 저장을 위한 리스트\n",
    "data = []\n",
    "\n",
    "# 파일 이름에서 정보 추출 및 wav 파일 duration 계산\n",
    "for file_path, file_name in file_list:\n",
    "    # pnum 추출\n",
    "    pnum_match = re.search(pnum_pattern, file_name)\n",
    "    pnum = int(pnum_match.group()[-2:])\n",
    "    # start_second 추출\n",
    "    start_match = re.search(dt_pattern, file_name)\n",
    "    start_second = start_match.group()\n",
    "\n",
    "    # duration 계산\n",
    "    with wave.open(file_path, 'rb') as wav_file:\n",
    "        frames = wav_file.getnframes()\n",
    "        rate = wav_file.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "    \n",
    "    # 데이터 추가\n",
    "    data.append([pnum, start_second, duration])\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "worker_df = pd.DataFrame(data, columns=['pnum', 'start_second', 'worker_audio_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([\n",
    "                    customer_df.set_index(['pnum', 'start_second']),\n",
    "                    worker_df.set_index(['pnum', 'start_second'])],\n",
    "                    axis=1, join='inner').reset_index()\n",
    "\n",
    "final_df['start_second'] = pd.to_datetime(final_df['start_second'],format='%Y-%m-%d_%H%M%S')\n",
    "dest_path = os.path.join(envs['DATA_PATH'],'3_feature_extraction','CAL_AUDIO_statistics','audio_all_duration.csv')\n",
    "final_df.to_csv(dest_path,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function \n",
    "def attatch_prefix_condition(df, prefix,exclude_col = ['pnum','start_second','end','date','matching']):\n",
    "    df.columns = [f\"{prefix}_{col}\" if col not in exclude_col else col for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio\n",
    "def load_audio(path):\n",
    "    customer_audio =  pd.read_csv(os.path.join(path, 'customer_audio.csv'),parse_dates=['start_second']).drop(['min_rolloff_min'],axis=1)\n",
    "    customer_audio = attatch_prefix_condition(customer_audio,'(S)_customer_audio')\n",
    "\n",
    "    worker_audio =  pd.read_csv(os.path.join(path, 'worker_audio.csv'),parse_dates=['start_second']).drop(['min_energy','min_rolloff_min'],axis=1)\n",
    "    worker_audio = attatch_prefix_condition(worker_audio,'(R)_worker_audio')\n",
    "\n",
    "    audio_duration = pd.read_csv(os.path.join(path,\"audio_all_duration.csv\"),parse_dates=['start_second'])\n",
    "    audio_duration.columns = ['pnum','start_second','(S)_customer_audio_duration','(R)_worker_audio_duration']\n",
    "\n",
    "    final_df = pd.concat([customer_audio.set_index(['pnum', 'start_second']),\n",
    "                        worker_audio.set_index(['pnum', 'start_second']),\n",
    "                        audio_duration.set_index(['pnum','start_second'])],\n",
    "                        axis=1, join='outer').reset_index()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "path = os.path.join(envs['DATA_PATH'],'3_feature_extraction','CAL_AUDIO_statistics')\n",
    "audio = load_audio(path)\n",
    "audio.to_csv(os.path.join(path,'audio.csv'),index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_781438/3973282549.py:139: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  text_df = pd.concat([text_df, pd.DataFrame(text_row)], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "audio_root = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO','customer')\n",
    "file_list = []\n",
    "\n",
    "# 오디오 파일 목록 생성\n",
    "for root, dirs, files in os.walk(audio_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.srt'):\n",
    "            file_list.append([root,os.path.join(root, file),file])\n",
    "\n",
    "audio_additional_root = os.path.join(envs['DATA_PATH'],'1_raw','CAL_AUDIO','audio_additional','customer')\n",
    "for root, dirs, files in os.walk(audio_additional_root):\n",
    "    for file in files:\n",
    "        if file.endswith('.srt'):\n",
    "            file_list.append([root,os.path.join(root, file),file])\n",
    "\n",
    "# 데이터프레임 초기화\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "# 정규 표현식 패턴으로 추출하기\n",
    "\n",
    "def open_srt_with_encoding(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'cp949', 'euc-kr']  # 시도할 인코딩 목록\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            print(f\"Trying to open the file with encoding: {encoding}\")\n",
    "            subtitles = pysrt.open(file_path, encoding=encoding)\n",
    "            print(\"File opened successfully!\")\n",
    "            return subtitles\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to open the file with encoding: {encoding}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "    raise ValueError(\"Unable to open the file with the provided encodings.\")\n",
    "\n",
    "\n",
    "text_df = pd.DataFrame(columns=['start_second', 'pnum','transcript_worker','transcript_customer','worker_total_turn','customer_total_turn'])\n",
    "check_file_path = []\n",
    "dt_pattern = r'\\d{4}-\\d{2}-\\d{2}_\\d{6}'\n",
    "pnum_pattern = r'[Pp](\\d{1,2})'\n",
    "\n",
    "# 각 파일에 대해 피처 추출 및 데이터프레임에 추가\n",
    "for root,file_path,file_name in file_list: \n",
    "    subtitles = pysrt.open(file_path) # 파일 열기\n",
    "    dt_name = re.search(dt_pattern, file_name).group()\n",
    "    dt_target = pd.to_datetime(dt_name,format='%Y-%m-%d_%H%M%S')\n",
    "    pnum_name = re.search(pnum_pattern,file_name).group()\n",
    "    pnum_int = int(pnum_name[1:])\n",
    "\n",
    "    rows= []\n",
    "    for subtitle in subtitles: \n",
    "        match = re.match(r'(Speaker\\s\\d+):\\s*(.*)', subtitle.text)\n",
    "\n",
    "        if match:\n",
    "            speaker = match.group(1)     # 화자 정보\n",
    "            text = match.group(2)        # 발화 내용\n",
    "        else:\n",
    "            speaker = None               # 화자 정보가 없을 때\n",
    "            text = subtitle.text         # 전체 텍스트를 발화 내용으로 설정\n",
    "\n",
    "        row = {\n",
    "            'Index': subtitle.index,\n",
    "            'Start Time': subtitle.start.to_time(),  # 시작 시간\n",
    "            'End Time': subtitle.end.to_time(),      # 종료 시간\n",
    "            'Speaker': speaker,                      # 화자\n",
    "            'Text': text                             # 발화 내용\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    if len(df['Speaker'].unique())==2:\n",
    "        # 'Index' 값이 1인 'Speaker' 정보를 기준으로 다른 행의 'Speaker'를 수정\n",
    "        worker_speaker = df.loc[df['Index'] == 1, 'Speaker'].values[0]  # Index가 1인 Speaker 정보 가져오기\n",
    "        # 해당 Speaker가 아닌 다른 Speaker들은 모두 'Customer'로 변경\n",
    "        df['Speaker'] = df['Speaker'].apply(lambda x: 'worker' if x == worker_speaker else 'customer')\n",
    "\n",
    "        df.to_csv(os.path.join(root,file_name.split('.')[0] + \".csv\"))\n",
    "\n",
    "        temp_row = []\n",
    "        # Worker와 Customer의 transcript 분리\n",
    "        worker_text = ' '.join(df.loc[df['Speaker'] == 'worker', 'Text'].tolist())\n",
    "        customer_text = ' '.join(df.loc[df['Speaker'] == 'customer', 'Text'].tolist())\n",
    "\n",
    "        # turn 수\n",
    "        worker_turn = len(df[df['Speaker']=='worker'])\n",
    "        customer_turn = len(df[df['Speaker']=='customer'])\n",
    "\n",
    "        text_row = {\n",
    "            'start_second' : [dt_target],\n",
    "            'pnum':[pnum_int],\n",
    "            'transcript_worker' : [worker_text],\n",
    "            'transcript_customer':[customer_text],\n",
    "            'worker_total_turn' : [worker_turn],\n",
    "            'customer_total_turn' : [customer_turn]\n",
    "        }\n",
    "        text_df = pd.concat([text_df, pd.DataFrame(text_row)], ignore_index=True)\n",
    "    elif len(df['Speaker'].unique())==3:\n",
    "        worker_speaker = df.loc[df['Index'] == 1, 'Speaker'].values[0]\n",
    "        \n",
    "        # 첫 번째 worker가 아닌 Speaker 중 가장 먼저 등장한 Speaker를 customer로 지정\n",
    "        other_speakers = df[df['Speaker'] != worker_speaker]['Speaker'].unique()\n",
    "        customer_speaker = other_speakers[0]  # 첫 번째 worker가 아닌 Speaker\n",
    "        \n",
    "        # Speaker를 worker, customer, co-worker로 재지정\n",
    "        df['Speaker'] = df['Speaker'].apply(\n",
    "            lambda x: 'worker' if x == worker_speaker else \n",
    "                    'customer' if x == customer_speaker else \n",
    "                    'co-worker'\n",
    "        )\n",
    "        df.to_csv(os.path.join(root, file_name.split('.')[0] + \".csv\"))\n",
    "\n",
    "        # Worker, Customer, Co-worker의 transcript 분리\n",
    "        worker_text = ' '.join(df.loc[df['Speaker'] == 'worker', 'Text'].tolist())\n",
    "        customer_text = ' '.join(df.loc[df['Speaker'] == 'customer', 'Text'].tolist())\n",
    "        coworker_text = ' '.join(df.loc[df['Speaker'] == 'co-worker', 'Text'].tolist())\n",
    "\n",
    "        # turn 수\n",
    "        worker_turn = len(df[df['Speaker'] == 'worker'])\n",
    "        customer_turn = len(df[df['Speaker'] == 'customer'])\n",
    "        coworker_turn = len(df[df['Speaker'] == 'co-worker'])\n",
    "\n",
    "        text_row = {\n",
    "            'start_second': [dt_target],\n",
    "            'pnum': [pnum_int],\n",
    "            'transcript_worker': [worker_text],\n",
    "            'transcript_customer': [customer_text],\n",
    "            'transcript_coworker': [coworker_text],\n",
    "            'worker_total_turn': [worker_turn],\n",
    "            'customer_total_turn': [customer_turn],\n",
    "            'coworker_total_turn': [coworker_turn]\n",
    "        }\n",
    "        text_df = pd.concat([text_df, pd.DataFrame(text_row)], ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        check_file_path .append([file_path,len(df['Speaker'].unique())])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiwi = Kiwi()\n",
    "\n",
    "# Fillna\n",
    "text_df['transcript_coworker'] = text_df['transcript_coworker'].fillna(\" \")\n",
    "text_df['coworker_total_turn'] = text_df['coworker_total_turn'].fillna(0)\n",
    "\n",
    "# Normalization\n",
    "def normalize_to_base_form(text):\n",
    "    # 형태소 분석을 통해 각 단어의 기본형 추출\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    normalized_text = ''\n",
    "    \n",
    "    # 이전 토큰의 끝 위치를 추적\n",
    "    previous_end = 0\n",
    "    for token in tokens:\n",
    "        # 이전 토큰의 끝 위치와 현재 토큰의 시작 위치가 다르면 띄어쓰기가 있었다고 판단\n",
    "        if token.start > previous_end:\n",
    "            normalized_text += ' '\n",
    "        \n",
    "        # 기본형이 존재하면 base_form을 사용, 없으면 form을 사용\n",
    "        normalized_text += token.base_form if token.base_form else token.form\n",
    "        \n",
    "        # 현재 토큰의 끝 위치를 갱신\n",
    "        previous_end = token.end\n",
    "    \n",
    "    return normalized_text\n",
    "\n",
    "text_df['transcript_worker_normalized'] = text_df['transcript_worker'].apply(normalize_to_base_form)\n",
    "text_df['transcript_customer_normalized'] = text_df['transcript_customer'].apply(normalize_to_base_form)\n",
    "text_df['transcript_coworker_normalized'] = text_df['transcript_coworker'].apply(normalize_to_base_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotional Lexcion-based feature\n",
    "    * Total Emotion word Count (TEC): 문서 내 감정과 연관된 단어의 개수를 카운트하는 feature.\n",
    "    * Total Emotion word Intensity (TEI): 문서에 포함된 단어의 감정 강도 점수를 합산한 feature.\n",
    "\n",
    "* github link: https://github.com/park1200656/KnuSentiLex?tab=readme-ov-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiwi 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 감성 사전 불러오기 및 polarity 값을 int로 변환\n",
    "with open('/SentiWord_info.json', encoding='utf-8-sig', mode='r') as f: \n",
    "    SentiWord_info = json.load(f)\n",
    "sentiword_df = pd.DataFrame(SentiWord_info)\n",
    "\n",
    "# polarity 값을 int로 변환하여 딕셔너리 생성\n",
    "sentiword_dict = {word: int(polarity) for word, polarity in zip(sentiword_df['word'], sentiword_df['polarity'])}\n",
    "\n",
    "# 문장별 긍정/부정 점수 및 단어 개수 계산 함수\n",
    "def calculate_sentence_emotions(text):\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    \n",
    "    # 초기 값 설정\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    \n",
    "    # 각 토큰에 대해 감정 단어 확인 및 점수와 개수 계산\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        if word in sentiword_dict:\n",
    "            polarity = sentiword_dict[word]\n",
    "            if polarity > 0:\n",
    "                positive_score += polarity\n",
    "                positive_count += 1\n",
    "            elif polarity < 0:\n",
    "                negative_score += abs(polarity)\n",
    "                negative_count += 1\n",
    "    \n",
    "    return positive_score, negative_score, positive_count, negative_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 점수 및 단어 개수를 열에 추가\n",
    "text_df[['(R)_worker_transcript_positive_score', '(R)_worker_transcript_negative_score', '(R)_worker_transcript_positive_count', '(R)_worker_transcript_negative_count']] = \\\n",
    "    text_df['transcript_worker_normalized'].apply(lambda x: pd.Series(calculate_sentence_emotions(x)))\n",
    "\n",
    "# 감정 점수 및 단어 개수를 열에 추가\n",
    "text_df[['(S)_customer_transcript_positive_score', '(S)_customer_transcript_negative_score', '(S)_customer_transcript_positive_count', '(S)_customer_transcript_negative_count']] = \\\n",
    "    text_df['transcript_customer_normalized'].apply(lambda x: pd.Series(calculate_sentence_emotions(x)))\n",
    "\n",
    "text_df[['(S)_coworker_transcript_positive_score', '(S)_coworker_transcript_negative_score', '(S)_coworker_transcript_positive_count', '(S)_coworker_transcript_negative_count']] = \\\n",
    "    text_df['transcript_coworker_normalized'].apply(lambda x: pd.Series(calculate_sentence_emotions(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분류\n",
    "\n",
    "kiwi = Kiwi()\n",
    "def tokenize_with_kiwi(text):\n",
    "    tokens = kiwi.analyze(text)[0][0]  # 형태소 분석 결과\n",
    "    return [token[0] for token in tokens]  # 형태소만 추출 (token[0]이 단어)\n",
    "\n",
    "\n",
    "# TF-IDF Vectorizer - worker\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_with_kiwi,max_features=50, min_df = 10, max_df = 0.7)  # lowercase=False: 소문자 변환 방지\n",
    "tfidf_matrix = vectorizer.fit_transform(text_df['transcript_worker_normalized'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)\n",
    "modified_words = [f\"(R)_worker_transcript_{word}\" for word in words]\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns = modified_words)\n",
    "text_df = pd.concat([text_df, tfidf_df], axis=1)\n",
    "\n",
    "# TF-IDF Vectorizer - customer\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_with_kiwi,max_features=50, min_df = 10, max_df = 0.7)  # lowercase=False: 소문자 변환 방지\n",
    "tfidf_matrix = vectorizer.fit_transform(text_df['transcript_customer_normalized'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)\n",
    "modified_words = [f\"(S)_customer_transcript_{word}\" for word in words]\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns =modified_words)\n",
    "text_df = pd.concat([text_df, tfidf_df], axis=1)\n",
    "\n",
    "\n",
    "# TF-IDF Vectorizer - coworker\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_with_kiwi, max_features=50, min_df = 10, max_df = 0.7)  # lowercase=False: 소문자 변환 방지\n",
    "tfidf_matrix = vectorizer.fit_transform(text_df['transcript_coworker_normalized'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)\n",
    "modified_words = [f\"(S)_coworker_transcript_{word}\" for word in words]\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns =modified_words)\n",
    "text_df = pd.concat([text_df, tfidf_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dest_path = os.path.join(envs['DATA_PATH'],'3_feature_extraction','CALL_AUDO_statistics','transcript.csv')\n",
    "text_df.to_csv(text_dest_path ,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
